import cPickle
import random
import classification_starter as classif
import numpy as np

def unpickle(file):
    """Loads and returns a pickled data structure in the given `file` name
    Example usage:
        data = unpickle('output/U_20_std')
    """
    fo = open(file, 'rb')
    data = cPickle.load(fo)
    fo.close()
    return data

def pickle(data, file):
    """Dumps data to a file
    Example usage:
        pickle(U, 'output/U_20_std')
    """
    fo = open(file,'wb')
    cPickle.dump(data,fo)
    fo.close()

# Default value for parameters
# If only some values are provided, fills in for the rest (to prevent errors)
def defParams(params={}):
    if 'load' not in params:
        params['load'] = None
    if 'extractFile' not in params:
        params['extractFile'] = None
    if 'splitFile' not in params:
        params['splitFile'] = None
    if 'writePredict' not in params:
        params['writePredict'] = False
    if 'outputFile' not in params:
        params['outputFile'] = None
    if 'splitMethod' not in params:
        params['splitMethod'] = 0

    return params

def splitData(fds, targets, ids, withhold=0, splitMethod=0):
    #Combine the 3 lists into 1 list to match the indices
    data = zip(fds, targets, ids)
    #Shuffles the data and divides them into training and testing data
    if splitMethod == 2:
        trainData = data[withhold:]
        testData = data[:withhold]
    else:
        if splitMethod == 0:
            random.shuffle(data)
        trainData = data[:(len(data) - withhold)]
        testData = data[(len(data) - withhold):]
    #Divides the list into its components
    fds, targets, ids = zip(*trainData)
    fdsTest, targetsTest, idsTest = zip(*testData)

    return fds, targets, ids, fdsTest, targetsTest, idsTest

def loadData(params, withhold, ffs, trainDir="train", testDir="test"):
    """
    loads the movie data

    arguments:
        params      : dict with several keys:
            load        : loading mode; either: 'extract' to load from
                        `params['extractFile']`, 'split' to load from
                        `params['splitFile']`, or None to extract features and
                        save to `params['extractFile']` and/or
                        `params['splitFile']`.
            extractFile : file to load/save extracted features to/from,
                        depending on loading mode
            splitFile   : file to load/save split data to/from,
                        depending on loading mode
        withhold    : number of data points to withhold for cross-validation
        ffs         : list of feature functions
        trainDir   : path to training file (train.xml)
        testDir    : path to test cases file

    returns:

    """
    # load data from `params['splitFile']`
    if params['load']=='split':
        X_train, y_train, train_ids,X_test,y_test,test_ids = unpickle(params['splitFile'])
        print "loaded %d fds" % len(train_ids)
        print "withholding %d of %d fds" % (len(test_ids), len(train_ids))
    else:
        # load data from scratch
        if params['load']==None:
            fds, targets, train_ids = classif.extract_feats_helper(ffs, trainDir)
            print "loaded %d fds" % len(fds)
            if params['extractFile'] != None:
                pickle((fds,targets,train_ids),params['extractFile'])
        # load data from `params['extractFile']`, but split it anew
        elif params['load']=='extract':
            fds,targets,train_ids=unpickle(params['extractFile'])
            print "loaded %d fds" % len(fds)

        # load the test data from the testcases file
        if withhold==0:
            X_train,feat_dict = classif.make_design_mat(fds)
            y_train=np.array(targets)
            X_test,_,y_test,test_ids = classif.extract_feats(ffs, testDir, global_feat_dict=feat_dict)
            train_ids = []
        # withhold some of the training data into test data
        else:
            fds, targets, train_ids, fdsTest, targetsTest, test_ids = splitData(fds, targets, train_ids, withhold, params['splitMethod'])
            X_train,feat_dict = classif.make_design_mat(fds)
            X_test,_ = classif.make_design_mat(fdsTest, feat_dict)
            y_train=np.array(targets)
            y_test=np.array(targetsTest)

        if params['splitFile'] != None:
            print "Writing split file..."
            pickle((X_train, y_train, train_ids,X_test,y_test,test_ids), params['splitFile'])
            print"Done writing split file"

    return X_train,y_train,train_ids, X_test,y_test,test_ids